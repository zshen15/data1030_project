{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    IDLink    Topic  PublishDate  SentimentTitle  SentimentHeadline  Facebook  \\\n",
      "0  99248.0    obama     0.000000        0.000000          -0.053300        -1   \n",
      "1  10423.0  economy     0.453492        0.208333          -0.156386        -1   \n",
      "\n",
      "   GooglePlus  LinkedIn  Facebook_pro  GooglePlus_pro  LinkedIn_pro  \\\n",
      "0          -1        -1           0.0             0.0           0.0   \n",
      "1          -1        -1           0.0             0.0           0.0   \n",
      "\n",
      "   x0_economy  x0_microsoft  x0_obama  x0_palestine  BestPlat  \n",
      "0         0.0           0.0       1.0           0.0         0  \n",
      "1         1.0           0.0       0.0           0.0         0  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/News_pro.csv')\n",
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PublishDate  SentimentTitle  SentimentHeadline  x0_economy  x0_microsoft  \\\n",
      "0     0.000000        0.000000          -0.053300         0.0           0.0   \n",
      "1     0.453492        0.208333          -0.156386         1.0           0.0   \n",
      "2     0.688586       -0.425210           0.139754         1.0           0.0   \n",
      "3     0.905065        0.000000           0.026064         1.0           0.0   \n",
      "4     0.905066        0.000000           0.141084         1.0           0.0   \n",
      "5     0.905067       -0.075378           0.036773         0.0           1.0   \n",
      "6     0.975033        0.000000          -0.005906         0.0           0.0   \n",
      "7     0.905071        0.083333           0.103003         0.0           0.0   \n",
      "8     0.905075       -0.173925          -0.050185         0.0           0.0   \n",
      "9     0.905077       -0.059536          -0.081715         0.0           1.0   \n",
      "\n",
      "   x0_obama  x0_palestine  BestPlat  \n",
      "0       1.0           0.0         0  \n",
      "1       0.0           0.0         0  \n",
      "2       0.0           0.0         0  \n",
      "3       0.0           0.0         0  \n",
      "4       0.0           0.0         0  \n",
      "5       0.0           0.0         0  \n",
      "6       0.0           1.0         4  \n",
      "7       1.0           0.0         0  \n",
      "8       0.0           1.0         0  \n",
      "9       0.0           0.0         0  \n"
     ]
    }
   ],
   "source": [
    "# drop IDLink and Topic\n",
    "# drop Facebook GooglePlus and LinkedIn\n",
    "# maybe I can even drop _pro for they have been truned into BestPlat\n",
    "df = df.drop(columns=['IDLink', 'Topic', 'Facebook','GooglePlus','LinkedIn'])\n",
    "df = df.drop(columns=['Facebook_pro','GooglePlus_pro','LinkedIn_pro'])\n",
    "print(df.head(10))\n",
    "df_origin = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thus, we have\n",
    "# x: PublishDate, SentimentTitle, SentimentHeadline, Topic(*4)\n",
    "# y: BestPlat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93239, 8)\n",
      "PublishDate          0.0\n",
      "SentimentTitle       0.0\n",
      "SentimentHeadline    0.0\n",
      "x0_economy           0.0\n",
      "x0_microsoft         0.0\n",
      "x0_obama             0.0\n",
      "x0_palestine         0.0\n",
      "BestPlat             0.0\n",
      "dtype: float64\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "df.replace(to_replace=' ?',value = np.nan, inplace=True)\n",
    "\n",
    "print(df.shape)\n",
    "print(df.isnull().sum(axis=0)/df.shape[0])\n",
    "print(sum(df.isnull().sum(axis=1)!=0)/df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is no missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate out the feature matrix (X) and the target variable (y).\n",
    "X = df.drop(columns=['BestPlat'],inplace=False)\n",
    "y = df['BestPlat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    53721\n",
      "4    14875\n",
      "3    12105\n",
      "0     5745\n",
      "5     4496\n",
      "2     2297\n",
      "Name: BestPlat, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    0.576164\n",
      "4    0.159536\n",
      "3    0.129828\n",
      "0    0.061616\n",
      "5    0.048220\n",
      "2    0.024636\n",
      "Name: BestPlat, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 0: if there are two or more -1, which means that the news is not posted in any of the platforms. (can be dropped)\n",
    "# 1: F\n",
    "# 2: G\n",
    "# 3: L\n",
    "# 4: if the news has been posted on all three platform but all three platforms has zero popularity. (indifference)\n",
    "# 5: all the other samples, f = g > l etc. (can be dropped)\n",
    "\n",
    "per = y.value_counts()/y.shape\n",
    "print(per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    0.647257\n",
      "4    0.179221\n",
      "3    0.145847\n",
      "2    0.027675\n",
      "Name: BestPlat, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# drop the rows when BestPlat = 0 or 5 (the percentage is not very high so we can do this.)\n",
    "df = df.set_index('BestPlat')\n",
    "df = df.drop([0,5], axis=0)\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# generate new X and y\n",
    "X = df.drop(columns=['BestPlat'],inplace=False)\n",
    "y = df['BestPlat']\n",
    "per = y.value_counts()/y.shape\n",
    "print(per)\n",
    "\n",
    "# 1: F\n",
    "# 2: G\n",
    "# 3: L\n",
    "# 4: indifference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82998, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split my data in a stratified manner into other and test (20% in `test`) \n",
    "# Then split other into 5 stratified folds. \n",
    "# 4 of those folds will be used for training, the last fold will be CV. \n",
    "# Loop through the 5 options the CV fold can be selected.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.values \n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_pipeline_kfold_LR(X,y,random_state,n_folds=5):\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state, stratify = y)\n",
    "    kf = StratifiedKFold(n_splits=n_folds, shuffle=True,random_state=random_state)\n",
    "\n",
    "    CV_scores = []\n",
    "    test_scores = []\n",
    "\n",
    "    for train_index, CV_index in kf.split(X_other,y_other):\n",
    "        X_train, X_CV = X_other[train_index], X_other[CV_index]\n",
    "        y_train, y_CV = y_other[train_index], y_other[CV_index]\n",
    "\n",
    "        # tune lasso hyper-parameter, alpha\n",
    "        alpha = np.logspace(-3,3,5)\n",
    "        train_score = []\n",
    "        CV_score = []\n",
    "        regs = []\n",
    "        for a in alpha:\n",
    "            # print(\"a\",a)\n",
    "            reg = LogisticRegression(penalty='l1', C=1/a, solver=\"saga\", max_iter=10000, multi_class=\"multinomial\")\n",
    "            reg.fit(X_train, y_train)\n",
    "            train_score.append(accuracy_score(y_train, reg.predict(X_train)))\n",
    "            CV_score.append(accuracy_score(y_CV, reg.predict(X_CV)))\n",
    "            regs.append(reg)\n",
    "            # print('end')\n",
    "        # find the best alpha in this fold\n",
    "        best_alpha = alpha[np.argmax(CV_score)]\n",
    "        # grab the best model\n",
    "        reg = regs[np.argmax(CV_score)]\n",
    "        CV_scores.append(np.max(CV_score))\n",
    "        # calculate test score using thee best model\n",
    "        test_scores.append(accuracy_score(y_test, reg.predict(X_test)))\n",
    "        \n",
    "    print(\"best alpha is \", best_alpha)\n",
    "    return CV_scores, test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha is  0.001\n",
      "best alpha is  1.0\n",
      "best alpha is  1.0\n",
      "best alpha is  1.0\n",
      "best alpha is  1.0\n",
      "test Score: 0.66 +/- 0.0\n"
     ]
    }
   ],
   "source": [
    "test_scores = [] \n",
    "for i in range(5): \n",
    "    grid, test_score = ML_pipeline_kfold_LR(X,y,i * 610, 5) \n",
    "    test_scores.append(test_score) \n",
    "print('test Score:', np.around(np.mean(test_scores),2), \"+/-\", np.around(np.std(test_scores),2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.647257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha is  3.593813663804626\n",
      "best alpha is  0.2782559402207126\n",
      "best alpha is  3.593813663804626\n",
      "test Score: 0.66 +/- 0.0\n"
     ]
    }
   ],
   "source": [
    "def ML_pipeline_kfold_LR(X,y,random_state,n_folds=5):\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state, stratify = y)\n",
    "    kf = StratifiedKFold(n_splits=n_folds, shuffle=True,random_state=random_state)\n",
    "\n",
    "    CV_scores = []\n",
    "    test_scores = []\n",
    "\n",
    "    for train_index, CV_index in kf.split(X_other,y_other):\n",
    "        X_train, X_CV = X_other[train_index], X_other[CV_index]\n",
    "        y_train, y_CV = y_other[train_index], y_other[CV_index]\n",
    "\n",
    "        # tune lasso hyper-parameter, alpha\n",
    "        alpha = np.logspace(-5,5,10)\n",
    "        train_score = []\n",
    "        CV_score = []\n",
    "        regs = []\n",
    "        for a in alpha:\n",
    "            # print(\"a\",a)\n",
    "            reg = LogisticRegression(penalty='l1', C=1/a, solver=\"saga\", max_iter=10000, multi_class=\"multinomial\")\n",
    "            reg.fit(X_train, y_train)\n",
    "            train_score.append(accuracy_score(y_train, reg.predict(X_train)))\n",
    "            CV_score.append(accuracy_score(y_CV, reg.predict(X_CV)))\n",
    "            regs.append(reg)\n",
    "            # print('end')\n",
    "        # find the best alpha in this fold\n",
    "        best_alpha = alpha[np.argmax(CV_score)]\n",
    "        # grab the best model\n",
    "        reg = regs[np.argmax(CV_score)]\n",
    "        CV_scores.append(np.max(CV_score))\n",
    "        # calculate test score using thee best model\n",
    "        test_scores.append(accuracy_score(y_test, reg.predict(X_test)))\n",
    "        \n",
    "    print(\"best alpha is \", best_alpha)\n",
    "    return CV_scores, test_scores\n",
    "\n",
    "test_scores = [] \n",
    "for i in range(3): \n",
    "    grid, test_score = ML_pipeline_kfold_LR(X,y,i * 610, 5) \n",
    "    test_scores.append(test_score) \n",
    "print('test Score:', np.around(np.mean(test_scores),2), \"+/-\", np.around(np.std(test_scores),2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6551204819277109, 0.6569879518072289, 0.6553614457831325, 0.6568072289156627, 0.6550602409638554], [0.6571686746987951, 0.6557228915662651, 0.6571686746987951, 0.6571084337349398, 0.6574096385542169], [0.6575301204819277, 0.6569879518072289, 0.6569879518072289, 0.6557228915662651, 0.6560240963855422]]\n",
      "0.0008430483213251509\n"
     ]
    }
   ],
   "source": [
    "print(test_scores)\n",
    "print(np.std(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha is  3.593813663804626\n",
      "best alpha is  0.2782559402207126\n",
      "best alpha is  3.593813663804626\n",
      "best alpha is  0.2782559402207126\n",
      "best alpha is  1e-05\n",
      "test Score: 0.66 +/- 0.0\n",
      "time: 1291.3945047855377\n"
     ]
    }
   ],
   "source": [
    "def ML_pipeline_kfold_LR(X,y,random_state,n_folds=5):\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state, stratify = y)\n",
    "    kf = StratifiedKFold(n_splits=n_folds, shuffle=True,random_state=random_state)\n",
    "\n",
    "    CV_scores = []\n",
    "    test_scores = []\n",
    "\n",
    "    for train_index, CV_index in kf.split(X_other,y_other):\n",
    "        X_train, X_CV = X_other[train_index], X_other[CV_index]\n",
    "        y_train, y_CV = y_other[train_index], y_other[CV_index]\n",
    "\n",
    "        # tune lasso hyper-parameter, alpha\n",
    "        alpha = np.logspace(-5,5,10)\n",
    "        train_score = []\n",
    "        CV_score = []\n",
    "        regs = []\n",
    "        for a in alpha:\n",
    "            # print(\"a\",a)\n",
    "            reg = LogisticRegression(penalty='l1', C=1/a, solver=\"saga\", max_iter=10000, multi_class=\"multinomial\")\n",
    "            reg.fit(X_train, y_train)\n",
    "            train_score.append(accuracy_score(y_train, reg.predict(X_train)))\n",
    "            CV_score.append(accuracy_score(y_CV, reg.predict(X_CV)))\n",
    "            regs.append(reg)\n",
    "            # print('end')\n",
    "        # find the best alpha in this fold\n",
    "        best_alpha = alpha[np.argmax(CV_score)]\n",
    "        # grab the best model\n",
    "        reg = regs[np.argmax(CV_score)]\n",
    "        CV_scores.append(np.max(CV_score))\n",
    "        # calculate test score using thee best model\n",
    "        test_scores.append(accuracy_score(y_test, reg.predict(X_test)))\n",
    "        \n",
    "    print(\"best alpha is \", best_alpha)\n",
    "    return CV_scores, test_scores\n",
    "\n",
    "s = time.time()\n",
    "test_scores = [] \n",
    "for i in range(5): \n",
    "    grid, test_score = ML_pipeline_kfold_LR(X,y,i * 610, 5) \n",
    "    test_scores.append(test_score) \n",
    "e = time.time()\n",
    "print('test Score:', np.around(np.mean(test_scores),2), \"+/-\", np.around(np.std(test_scores),2)) \n",
    "t = e-s\n",
    "print('time:', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 5\n",
    "# alpha = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6551204819277109, 0.6569879518072289, 0.6553614457831325, 0.6568072289156627, 0.6550602409638554], [0.6571686746987951, 0.6557228915662651, 0.6571686746987951, 0.6571084337349398, 0.6574096385542169], [0.6575301204819277, 0.6569879518072289, 0.6569879518072289, 0.6557228915662651, 0.6560240963855422], [0.6551204819277109, 0.6551807228915663, 0.656566265060241, 0.6554819277108433, 0.6555421686746988], [0.6542168674698795, 0.6546987951807229, 0.6546385542168675, 0.6546385542168675, 0.6544578313253012]]\n",
      "0.0010407462958729847\n"
     ]
    }
   ],
   "source": [
    "print(test_scores)\n",
    "print(np.std(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import defaultdict\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
